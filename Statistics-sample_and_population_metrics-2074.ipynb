{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnbRHgLFCorJ"
   },
   "source": [
    "# Introduction To Statistics - Sample Vs Population Metrics\n",
    "\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXgoFu4-CorK"
   },
   "source": [
    "## Learning Objectives\n",
    "By the end of this train, you should be able to:\n",
    "\n",
    "* Differentiate between sample and population metrics,\n",
    "* Understand where the Central Limit theorem is utilised, and\n",
    "* Describe the function and measurement of confidence intervals.\n",
    "\n",
    "## Outline\n",
    "To do this we will:\n",
    "\n",
    "* Examine sample and population mean and variance,\n",
    "* Look at the Central Limit theorem, and\n",
    "* Discuss confidence intervals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tnMk4Ce-CorM"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In statistics, we refer to a *population* as the complete pool from which a sample can be drawn. This pool could consist of people, objects, events, categories, measurements, or virtually any set of entities. When considering the potential size of a population, it is often considered impractical to *test all of its data* for two reasons: \n",
    "   \n",
    "   - It is often not feasible, and \n",
    "   - It can be extremely computationally expensive to do so. \n",
    "\n",
    "Instead, we can try to estimate a population using *sample statistics*. An example of this would be a scenario in which we would like to test 500 patients from Johannesburg General (Charlotte Maxeke) Hospital, and then generalise the results to the rest of Johannesburg's public hospital system. The former sample is obtainable, while the latter would need to cover possibly tens of thousands of individuals across a large geographic area. However, how *representative* would our sample be seeing that it is far smaller than the total population, and is limited to only one hospital site? This question of *representativeness* is a primary concern when working with sample statistics. \n",
    "\n",
    "Consider below some of the differences in notation between population and sample statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAwYx3XBCorL"
   },
   "source": [
    "![image](http://www.astrocyte.in/articles/2014/1/1/images/Astrocyte_2014_1_1_62_131867_t1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UiYK1DaWVJGR"
   },
   "source": [
    "The aim within this train is to familiarise ourselves with some of these parameters - both from a population and sample statistic perspective.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZnCUqfynCorQ"
   },
   "source": [
    "## Mean and Variance\n",
    "\n",
    "Suppose that we are interested in the salaries of data scientists across the globe (and why wouldn't we be??). It's an impossible task to know the distribution of **ALL** these salaries; in practice, that would require information on the salary of every data scientist. We consequently end up relying on inferences made from a representative sample of data scientists. The true values of the population mean and variance are in principle unknowable.\n",
    "\n",
    "We can however calculate a sample mean and variance. The mean $\\bar{x}$ is simply the average of the observations $x_t$, where $t = 1, 2, \\ldots, n$:\n",
    "\n",
    "$$\\bar{x} = \\displaystyle \\frac{1}{n} \\sum_{t=1}^n x_t.$$\n",
    "\n",
    "The sample variance is calculated as:\n",
    "\n",
    "$$s^2_X = \\displaystyle \\frac{1}{n-1} \\sum_{t=1}^n (X_t - \\bar{x})^2.$$\n",
    "\n",
    "If you're paying attention, you may be asking why we divide by $n-1$ here, rather than $n$, as seems intuitive and as we did for the sample mean. While a little technical at this stage, this has to do with wanting an unbiased estimate of the population variance (in other words, if we repeated the sample a very large number of times and averaged the sample variances, we'd want that average to be equal to the population variance). Technically, we lose a degree of freedom here because we've had to use the sample mean $\\bar{x}$ as our estimate of $\\mu$: the sample mean together with $n-1$ of the observations determine the value of the $n$th observation; this is no longer a free parameter. If you don't get that, don't sweat it too much: what's important at this stage is that you know that if we want our sample variance to be unbiased, we must use a divisor of $n-1$ rather than $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QbahA-8CorR"
   },
   "source": [
    "## Central Limit Theorem \n",
    "\n",
    "It's time now to introduce the concept of a sampling distribution, but first let's remind ourselves of a tool that will prove valuable in this quest: the Central Limit Theorem.\n",
    "\n",
    "The Central Limit Theorem states that if a random variable $X$ is the sum of a large number of independent, identically distributed random outcomes, it will approximately follow a normal distribution, *even if the underlying random variables are not normally distributed*. Proof of this is beyond the scope of the course, but you should realise that this is an asymptotic result: it gets closer and closer to being true as the number of observations increases. As a general rule of thumb, 30 observations are required to rely on the Central Limit Theorem.\n",
    "\n",
    "In his work, [*Intro to Statistics - Probability and Distributions*](https://www.fd.cvut.cz/department/k611/PEDAGOG/THO_A/A_soubory/statistics_firstfive.pdf), Keon Hon introduces the following the Central Limit theorem in the following manner:  \n",
    "\n",
    "\"Start with a population with a given mean $\\mu$  and standard deviation $\\sigma$. Take samples of size $n$, where $n$ is a sufficiently large (generally at least 30) number, and compute the mean of each sample.\n",
    "\n",
    "With the following results:\n",
    "\n",
    "* The set of all sample means will be approximately normally distributed.\n",
    "\n",
    "* The mean of the set of samples will equal $\\mu$, the mean of the population.\n",
    "\n",
    "* The standard deviation, $\\sigma x$, of the set of sample means will be approximately $\\frac{\\sigma}{\\sqrt{n}}$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "URGIEAUDCorS"
   },
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "Using the central limit theorem, we can find the probability that a sample lies within an interval, but this is essentially the same as the probability of the population mean being estimated into a sample interval. \n",
    "\n",
    "As Keone puts it: \"We can determine how confident we are that the population mean lies within a certain interval of a sample mean.\"\n",
    "\n",
    "If a random variable is normally distributed, we can make statements about how certain we are that it will fall within certain multiples of the standard deviation about the mean. One well-known feature, with which you will become familiar, is that 95% of observations lie within 1.96 standard deviations of the mean. \n",
    "\n",
    "Before we get into the code, let's define some terms first:\n",
    "\n",
    " * **CDF**:\n",
    "     - Stands for \"Cumulative Distribution Function\"\n",
    "     - The CDF will tell us the probability of a value being below $x$.\n",
    "<br>\n",
    "\n",
    " * **PPF** :\n",
    "     - Stands for \"Percent Point Function\".\n",
    "     - This is the inverse of a CDF \n",
    "     - Another name for a _quantile function_.\n",
    "\n",
    "\n",
    "If you want to understand PPF's and CDF's in more detail, go to [this link](https://www.countbayesie.com/blog/2015/4/4/parameter-estimation-the-pdf-cdf-and-quantile-function) which describes those concepts and other distributions.\n",
    "\n",
    "Let's now look at things in a practical manner. We start by importing our de facto Python statistical library, Scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1283,
     "status": "ok",
     "timestamp": 1575296079903,
     "user": {
      "displayName": "Jason Webster",
      "photoUrl": "",
      "userId": "13254939673721675351"
     },
     "user_tz": -120
    },
    "id": "d8spCpzsCorS",
    "outputId": "5309b9c3-a761-42eb-ae10-2d91e21739ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950004209703559\n"
     ]
    }
   ],
   "source": [
    "# Show that roughly 95% of probability weight lies within 1.96 standard deviations§\n",
    "print(st.norm.cdf(1.96) - st.norm.cdf(-1.96))      # 95% confidence interval within 1.96 standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1575296079906,
     "user": {
      "displayName": "Jason Webster",
      "photoUrl": "",
      "userId": "13254939673721675351"
     },
     "user_tz": -120
    },
    "id": "v2oXjtRX0PMm",
    "outputId": "ec7c5cdc-6ed1-4844-963f-6c213ec4db19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.959963984540054\n",
      "1.6448536269514722\n",
      "2.5758293035489004\n",
      "2.807033768343811\n"
     ]
    }
   ],
   "source": [
    "# Calculate the exact confidence interval (CI) band: since we want a 95% CI, we want 2.5% above the upper bound and 2.5% below the lower\n",
    "# bound. Since the distribution is symmetric, we can simply figure out the point below which 97.5% of the \n",
    "# probability weight lies.\n",
    "print(st.norm.ppf(0.975))\n",
    "\n",
    "# repeat for 90%, 99% and 99.5% CIs\n",
    "print(st.norm.ppf(0.95))\n",
    "print(st.norm.ppf(0.995))\n",
    "print(st.norm.ppf(0.9975))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYA0U66WGosM"
   },
   "source": [
    "You must be wondering \"Where did that 1.96 come from and why is the one negative and the other is not?\". So let me introduce you to the world of Z-tables. There's a negative and a positive Z-table below (Table 1 & Table 2 respectively). So how would we use it?\n",
    "\n",
    "If you are 95% confident, that means you are 5% not confident. That 5% can be converted into a probability of 0.05. \n",
    "In distributions, they have 2-tails as in the standard bell curve. That means that our probability needs to also be divided by two so 0.05/2 = 0.025.\n",
    "\n",
    "The next step is to look at a Z-table. So how would you know when to use  a positive and a negative table you may ask? If you look at the decimal numbers in the center of the table, you'll notice that the values which are greater than 0.5 are on the positive table and values less than 0.5 are on the negative table. So therefore we use the NEGATIVE Z-table to find where the probability is 0.025 which should give a -1.9 value on the left column, and 0.06 value on the top row... and would you look at that! You will get -1.96 if you put those two numbers together!\n",
    "\n",
    "This can work in the for the positive z- table if we use 95% (which equates to 0.95 in probability terms). Can you figure out why 1.96 correlates to 0.975? Remember when we divided the 0.05 by 2! that would give 2.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1Lq8Wx_Rcua"
   },
   "source": [
    "**Table 1: Negative z-value Table**\n",
    "\n",
    "![image](http://www.z-table.com/uploads/2/1/7/9/21795380/9340559_orig.png)\n",
    "\n",
    "As you can see, if you trace the value of a - 1.96 Z value, you will find that the number correlating to that is 0.025.\n",
    "\n",
    "And here is the positive Z-table:\n",
    "\n",
    "**Table 2: Positive z-value table**\n",
    "\n",
    "![image](http://www.z-table.com/uploads/2/1/7/9/21795380/8573955.png?759)\n",
    "\n",
    "If you look at the positive Z value 0f 1.96, you will see that the number correlating to this is 0.975.\n",
    "\n",
    "So we can see that 95% of the data lies between 0.025 and 0.975.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HxskODbJCorX"
   },
   "source": [
    "How can we use this? Well, if we assume that the population variance $\\sigma^2$ is known then we can say with 95% confidence that \n",
    "\n",
    "$$\\displaystyle \\mu - 1.96 \\frac{\\sigma}{\\sqrt{n}} < \\bar{X} < \\mu + 1.96 \\frac{\\sigma}{\\sqrt{n}}.$$\n",
    "\n",
    "Just a little rearrangement should convince you that this is equivalent to saying that:\n",
    "\n",
    "$$\\displaystyle \\bar{X} - 1.96 \\frac{\\sigma}{\\sqrt{n}} < \\mu < \\bar{X} + 1.96 \\frac{\\sigma}{\\sqrt{n}}.$$\n",
    "\n",
    "For a 99% confidence interval, we'd substitute 2.58 for 1.96, but the principle remains the same for establishing confidence intervals around our estimate of the unknown population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_mouzIvCorY"
   },
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "#### Central Limit Thereom\n",
    "\n",
    "Foodland shoppers have a mean R60 grocery bill with a standard deviation of R40. What is the probability that a sample of 100 Foodland shoppers will have a mean grocery bill of over R70?\n",
    "\n",
    "#### Confidence Interval\n",
    "\n",
    "At a factory, batteries are produced with a standard deviation of 2.4 months.\n",
    "In a sample of 64 batteries, the mean life expectancy is 12.35. Find a 95% confidence interval estimate for the life expectancy of all batteries produced at the plant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilSLZ0b73sia"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Understanding statistics is fundamentally important for a data scientist. Population and Sample statistics play fundamental roles in making sure we optimise outcomes whilst preserving computational efficiency by subsetting and sampling. The Central Limit theorem helps to understand the population by just using a sample and the means and standard deviations of the two. Confidence intervals help us to create upper and lower limits when making inferential decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1LXyNuWw24j"
   },
   "source": [
    "## Solutions\n",
    "#### Central Limit Theorem\n",
    "Since the sample size is greater than 30, we can apply the Central Limit Theorem. By this theorem, the set of sample means of size 100 has mean R60 and standard deviation R40\n",
    "√\n",
    "100\n",
    "= R4. Thus, R70 represents a z-score of (R70 − R60) /\n",
    "R4 = 2.5.\n",
    "Since the set of sample means of size 100 is normally distributed, we can compare a z-score of 2.5 to the table of normal curve areas. The area between z = 0\n",
    "and z = 2.5 is 0.4938, so the probability is 0.5 - 0.4938 = 0.0062.\n",
    "\n",
    "#### Confidence Interval\n",
    "\n",
    "Since the sample has n larger than 30, the central limit theorem applies. Let\n",
    "the standard deviation of the set of sample means of size 64 be σx. Then by the\n",
    "central limit theorem, 2.4 = σx / √64\n",
    ", so σx = 0.3 months.\n",
    "\n",
    "Looking at the table of normal curve areas (or referring to section 4.3.3), 95%\n",
    "of the normal curve area is between the z-scores of -1.96 and 1.96. Since the\n",
    "standard deviation is 0.3, a z-score of −1.96 represents a raw score of -0.588\n",
    "months, and a z-score of 1.96 represents a raw score of 0.588 months. So we have\n",
    "95% confidence that the life expectancy will be between 12.35 − 0.588 = 11.762\n",
    "months and 12.35 + 0.588 = 12.938 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-RdNAcd_Q_r"
   },
   "source": [
    "## Appendix\n",
    "\n",
    "* [Intro to Statistics - Probability and Distributions, Keon Hon](https://www.fd.cvut.cz/department/k611/PEDAGOG/THO_A/A_soubory/statistics_firstfive.pdf)\n",
    "* [An Introduction to the Science of Statistics, Joseph Watkins](https://www.math.arizona.edu/~jwatkins/statbook.pdf)\n",
    "* [A Brief summary of some basic statistical concepts](https://towardsdatascience.com/machine-learning-probability-statistics-f830f8c09326)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "V2_Intro To Statistics - Sample Vs Population Metrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
